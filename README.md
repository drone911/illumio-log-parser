# illumio-log-parser

## Assumptions
1. As instructed, the program expects flow logs and lookup files as ascii files with the lookup file in csv format.
2. Since the log files contain protocol number, I have mapped the number to their protocols using IANA specification (as per aws) present in ```resource``` folder.
3. As instructed, I have used destination port and protocol to count tags and ports+protocols.

## How to run
1. Without specifying output file names.  
  ```
  python main.py path/to/flow/log path/to/lookup
  ```
2. Specifying output file names.  
  ```
  python main.py -tc /path/to/tag/count -pc /path/to/port-protocol/count path/to/flow/log path/to/lookup
  ```
  Or  
  ```
  python main.py --tag_count_path /path/to/tag/count --port_protocol_count_path /path/to/port-protocol/count path/to/flow/log path/to/lookup
  ```
3. Running tests 
```
python test.py
```
## Main Outputs
Here is an example run using the files ``example-flow-logs.txt`` and ``example-lookup.csv``.

<p align="center">
  <img src="https://github.com/drone911/illumio-log-parser/blob/main/img/example-run.PNG?raw=true" />
</p>

The output files generated by default are ```flow-tags-count.csv``` and ```port-protocol-count.csv```.
1. ```flow-tags-count.csv```

<p align="center">
  <img src="https://github.com/drone911/illumio-log-parser/blob/main/img/flow-tags-count.PNG?raw=true" />
</p>

2. ```port-protocol-count.csv```

<p align="center">
  <img src="https://github.com/drone911/illumio-log-parser/blob/main/img/flow-tags-count.PNG?raw=true" />
</p>

## Test Outputs
```test.py``` randomly generates the specified amount (as constant) of flow and lookup records, and shows the time taken by the aggregate logs function.  
1. For 100,000 records (10MB) in flow and 10,000 mappings in lookup:
<p align="center">
  <img src="https://github.com/drone911/illumio-log-parser/blob/main/img/test-output-100000-flow-10000-lookups.PNG?raw=true" />
</p>
2. For 1,000,000 records (100MB) in flow and 10,000 mappings in lookup:
<p align="center">
  <img src="https://github.com/drone911/illumio-log-parser/blob/main/img/test-output-1000000-flow-10000-lookups.PNG?raw=true" />
</p>
3. Generated flow and lookup files for these 2 test cases:
<p align="center">
  <img src="https://github.com/drone911/illumio-log-parser/blob/main/img/test-file-sizes.PNG?raw=true" />
</p>

## Obervations and Improvements
1. By using Python dictionaries for lookup table (which are essentially like HashMap in Java), the lookup table speed is in O(1) time.
2. For 10Mb of flows and 10,000 lookup mappings, the program took only 325 milliseconds.
3. To improve performance by utlizing all cores, we can use multiprocessing, where different worker processes read different chunks of the flows and produce aggregates, which are then combined by the parent process.
